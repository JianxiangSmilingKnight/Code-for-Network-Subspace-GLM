{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP1ozLLOTCOWHT5F0mDeQk+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"O56pry10i-N6","colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1717396222311,"user_tz":-480,"elapsed":40605,"user":{"displayName":"jianxiang wang","userId":"15849008681383759365"}},"outputId":"ef79b272-8056-454e-8de4-009dadc62021"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting karateclub\n","  Downloading karateclub-1.3.3.tar.gz (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m873.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting numpy<1.23.0 (from karateclub)\n","  Downloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting networkx<2.7 (from karateclub)\n","  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.10/dist-packages (from karateclub) (4.4.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from karateclub) (4.66.4)\n","Requirement already satisfied: python-louvain in /usr/local/lib/python3.10/dist-packages (from karateclub) (0.16)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from karateclub) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from karateclub) (1.11.4)\n","Collecting pygsp (from karateclub)\n","  Downloading PyGSP-0.5.1-py2.py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from karateclub) (4.3.2)\n","Collecting pandas<=1.3.5 (from karateclub)\n","  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from karateclub) (1.16.0)\n","Collecting python-Levenshtein (from karateclub)\n","  Downloading python_Levenshtein-0.25.1-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.0.0->karateclub) (6.4.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->karateclub) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->karateclub) (2023.4)\n","Collecting Levenshtein==0.25.1 (from python-Levenshtein->karateclub)\n","  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.8.0 (from Levenshtein==0.25.1->python-Levenshtein->karateclub)\n","  Downloading rapidfuzz-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->karateclub) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->karateclub) (3.5.0)\n","Building wheels for collected packages: karateclub\n","  Building wheel for karateclub (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for karateclub: filename=karateclub-1.3.3-py3-none-any.whl size=101984 sha256=96ab81e2bf5b366b20240a03d858e8d077abf9d36ed49f3fd172ae2e18933e50\n","  Stored in directory: /root/.cache/pip/wheels/62/bd/af/17e7ca6ba0ed144d22502780f5c0660a8e4985939dc6973a81\n","Successfully built karateclub\n","Installing collected packages: rapidfuzz, numpy, networkx, pandas, Levenshtein, python-Levenshtein, pygsp, karateclub\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.3\n","    Uninstalling networkx-3.3:\n","      Successfully uninstalled networkx-3.3\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.0.3\n","    Uninstalling pandas-2.0.3:\n","      Successfully uninstalled pandas-2.0.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.3.0+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","bigframes 1.6.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n","chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.22.4 which is incompatible.\n","cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n","cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.3.5 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.3.5 which is incompatible.\n","pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.22.4 which is incompatible.\n","plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n","plotnine 0.12.4 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n","rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n","statsmodels 0.14.2 requires pandas!=2.1.0,>=1.4, but you have pandas 1.3.5 which is incompatible.\n","tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n","xarray 2023.7.0 requires pandas>=1.4, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Levenshtein-0.25.1 karateclub-1.3.3 networkx-2.6.3 numpy-1.22.4 pandas-1.3.5 pygsp-0.5.1 python-Levenshtein-0.25.1 rapidfuzz-3.9.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"221f502ed4224189a45b5c7086a59431"}},"metadata":{}}],"source":["pip install karateclub"]},{"cell_type":"code","source":["import math\n","import networkx as nx\n","from karateclub import Diff2Vec\n","import numpy as np\n","import pandas as pd\n","import random\n","# Define the community memberships for each node\n","# Assign community labels to nodes\n","np.random.seed(1)\n","n=2000\n","p0 = pd.read_csv(\"P_0_2000.csv\")\n","p0=p0.values\n","p1 = pd.read_csv(\"P_1_2000.csv\")\n","p1=p1.values\n","p2 = pd.read_csv(\"P_2_2000.csv\")\n","p2=p2.values\n","\n","p0_net = np.zeros_like(p0, dtype=int)\n","\n","# Generate binary data based on the probabilities in the input matrix\n","for i in range(n):\n","    for j in range(i+1,n):\n","        p0_net[i][j] = np.random.choice([0, 1], p=[1 - p0[i][j], p0[i][j]])\n","\n","for i in range(n):\n","    for j in range(i):\n","        p0_net[i][j] = p0_net[j][i]\n","\n","p1_net = np.zeros_like(p1, dtype=int)\n","\n","# Generate binary data based on the probabilities in the input matrix\n","for i in range(n):\n","    for j in range(i+1,n):\n","        p1_net[i][j] = np.random.choice([0, 1], p=[1 - p1[i][j], p1[i][j]])\n","\n","for i in range(n):\n","    for j in range(i):\n","        p1_net[i][j] = p1_net[j][i]\n","\n","p2_net = np.zeros_like(p2, dtype=int)\n","\n","# Generate binary data based on the probabilities in the input matrix\n","for i in range(n):\n","    for j in range(i+1,n):\n","        p2_net[i][j] = np.random.choice([0, 1], p=[1 - p2[i][j], p2[i][j]])\n","\n","for i in range(n):\n","    for j in range(i):\n","        p2_net[i][j] = p2_net[j][i]\n","\n","rowsum=p0_net.sum(axis=1)\n","isoline=np.where(rowsum == 0)[0]\n","maxline=rowsum.argmax()\n","print(maxline)\n","print(isoline)\n","p0_net[isoline[0]][maxline]=1\n","p0_net[maxline][isoline[0]]=1\n","p0_net[isoline[1]][maxline]=1\n","p0_net[maxline][isoline[1]]=1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"IJTpbvriye6C","executionInfo":{"status":"ok","timestamp":1717398456036,"user_tz":-480,"elapsed":162885,"user":{"displayName":"jianxiang wang","userId":"15849008681383759365"}},"outputId":"e741cf54-76bb-4c50-e958-97fa3fae3a8b"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["397\n","[1076 1136]\n"]}]},{"cell_type":"code","source":["B=100\n","\n","G = nx.Graph(p0_net)\n","embedding_results = []\n","for _ in range(B):\n","    # Generate a stochastic block model graph based on the probability matrix\n","    # Perform node2vec embedding\n","    model=Diff2Vec(dimensions=3,diffusion_number=20,seed=_)\n","    model.fit(G)\n","    embeddings = model.get_embedding()\n","    embedding_results.append(embeddings)\n","\n","merged_matrix_2logn = np.concatenate(embedding_results, axis=1)\n","df = pd.DataFrame(merged_matrix_2logn)\n","df.to_csv('20_Diff2Vec_2logn_embedding_results.csv', index=False)\n","\n","\n","G = nx.Graph(p1_net)\n","embedding_results = []\n","for _ in range(B):\n","    # Generate a stochastic block model graph based on the probability matrix\n","    # Perform node2vec embedding\n","    model=Diff2Vec(dimensions=3,diffusion_number=20,seed=_)\n","    model.fit(G)\n","    embeddings = model.get_embedding()\n","    embedding_results.append(embeddings)\n","\n","merged_matrix_n12 = np.concatenate(embedding_results, axis=1)\n","df = pd.DataFrame(merged_matrix_n12)\n","df.to_csv('20_Diff2Vec_n12_embedding_results.csv', index=False)\n","\n","G = nx.Graph(p2_net)\n","embedding_results = []\n","for _ in range(B):\n","    # Generate a stochastic block model graph based on the probability matrix\n","    # Perform node2vec embedding\n","    model=Diff2Vec(dimensions=3,diffusion_number=20,seed=_)\n","    model.fit(G)\n","    embeddings = model.get_embedding()\n","    embedding_results.append(embeddings)\n","\n","merged_matrix_n23 = np.concatenate(embedding_results, axis=1)\n","df = pd.DataFrame(merged_matrix_n23)\n","df.to_csv('20_Diff2Vec_n23_embedding_results.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OS_CJVz03gVF","outputId":"69aba3c1-8d35-490b-edf2-e934722e1192"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.word2vec:Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n","WARNING:gensim.models.word2vec:Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n","WARNING:gensim.models.word2vec:Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n","WARNING:gensim.models.word2vec:Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n","WARNING:gensim.models.word2vec:Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n","WARNING:gensim.models.word2vec:Both hierarchical softmax and negative sampling are activated. This is probably a mistake. You should set either 'hs=0' or 'negative=0' to disable one of them. \n"]}]}]}